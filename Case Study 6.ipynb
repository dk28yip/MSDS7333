{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb9fc6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf \n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "#from pandas_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f17a6e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('all_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5a5208b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install the below libaries before importing\n",
    "\n",
    "#EDA using pandas-profiling\n",
    "#profile = ProfileReport(pd.read_csv('all_train.csv'), explorative=True)\n",
    "\n",
    "#Saving results to a HTML file\n",
    "#profile.to_file(\"output.html\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4be550e",
   "metadata": {},
   "source": [
    "### EDA is complete in the output file. There is no missing data. The response variable, label, is pretty closeley even, 3500879 to 3499121."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cfe12d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7000000 entries, 0 to 6999999\n",
      "Data columns (total 29 columns):\n",
      " #   Column   Dtype  \n",
      "---  ------   -----  \n",
      " 0   # label  float64\n",
      " 1   f0       float64\n",
      " 2   f1       float64\n",
      " 3   f2       float64\n",
      " 4   f3       float64\n",
      " 5   f4       float64\n",
      " 6   f5       float64\n",
      " 7   f6       float64\n",
      " 8   f7       float64\n",
      " 9   f8       float64\n",
      " 10  f9       float64\n",
      " 11  f10      float64\n",
      " 12  f11      float64\n",
      " 13  f12      float64\n",
      " 14  f13      float64\n",
      " 15  f14      float64\n",
      " 16  f15      float64\n",
      " 17  f16      float64\n",
      " 18  f17      float64\n",
      " 19  f18      float64\n",
      " 20  f19      float64\n",
      " 21  f20      float64\n",
      " 22  f21      float64\n",
      " 23  f22      float64\n",
      " 24  f23      float64\n",
      " 25  f24      float64\n",
      " 26  f25      float64\n",
      " 27  f26      float64\n",
      " 28  mass     float64\n",
      "dtypes: float64(29)\n",
      "memory usage: 1.5 GB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "189a148c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7000000 entries, 0 to 6999999\n",
      "Data columns (total 29 columns):\n",
      " #   Column    Dtype  \n",
      "---  ------    -----  \n",
      " 0   response  float64\n",
      " 1   f0        float64\n",
      " 2   f1        float64\n",
      " 3   f2        float64\n",
      " 4   f3        float64\n",
      " 5   f4        float64\n",
      " 6   f5        float64\n",
      " 7   f6        float64\n",
      " 8   f7        float64\n",
      " 9   f8        float64\n",
      " 10  f9        float64\n",
      " 11  f10       float64\n",
      " 12  f11       float64\n",
      " 13  f12       float64\n",
      " 14  f13       float64\n",
      " 15  f14       float64\n",
      " 16  f15       float64\n",
      " 17  f16       float64\n",
      " 18  f17       float64\n",
      " 19  f18       float64\n",
      " 20  f19       float64\n",
      " 21  f20       float64\n",
      " 22  f21       float64\n",
      " 23  f22       float64\n",
      " 24  f23       float64\n",
      " 25  f24       float64\n",
      " 26  f25       float64\n",
      " 27  f26       float64\n",
      " 28  mass      float64\n",
      "dtypes: float64(29)\n",
      "memory usage: 1.5 GB\n"
     ]
    }
   ],
   "source": [
    "# change # label to \"response\"\n",
    "df.rename(columns ={'# label': 'response'}, inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a0a868",
   "metadata": {},
   "source": [
    "### Split Data into test and train while scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc118e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X = df.loc[:, df.columns != 'response'].values\n",
    "\n",
    "y = df['response'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735ca722",
   "metadata": {},
   "source": [
    "### Grid Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f02c01b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\girar\\AppData\\Local\\Temp\\ipykernel_19044\\3312735626.py:28: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  regressor = tf.keras.wrappers.scikit_learn.KerasRegressor(create_model)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "3734/3734 [==============================] - 6s 1ms/step - loss: 0.4011 - accuracy: 0.8159 - val_loss: 0.3660 - val_accuracy: 0.8365\n",
      "Epoch 2/500\n",
      "3734/3734 [==============================] - 6s 2ms/step - loss: 0.3660 - accuracy: 0.8364 - val_loss: 0.3647 - val_accuracy: 0.8370\n",
      "Epoch 3/500\n",
      "3734/3734 [==============================] - 5s 1ms/step - loss: 0.3658 - accuracy: 0.8365 - val_loss: 0.3647 - val_accuracy: 0.8366\n",
      "Epoch 4/500\n",
      "3734/3734 [==============================] - 5s 1ms/step - loss: 0.3658 - accuracy: 0.8364 - val_loss: 0.3647 - val_accuracy: 0.8369\n",
      "Epoch 5/500\n",
      "3734/3734 [==============================] - 5s 1ms/step - loss: 0.3658 - accuracy: 0.8365 - val_loss: 0.3646 - val_accuracy: 0.8371\n",
      "58334/58334 [==============================] - 53s 905us/step - loss: 0.3650 - accuracy: 0.8369\n",
      "Epoch 1/500\n",
      "3734/3734 [==============================] - 6s 1ms/step - loss: 0.3942 - accuracy: 0.8202 - val_loss: 0.3648 - val_accuracy: 0.8369\n",
      "Epoch 2/500\n",
      "3734/3734 [==============================] - 5s 1ms/step - loss: 0.3655 - accuracy: 0.8367 - val_loss: 0.3646 - val_accuracy: 0.8371\n",
      "Epoch 3/500\n",
      "3734/3734 [==============================] - 5s 1ms/step - loss: 0.3655 - accuracy: 0.8366 - val_loss: 0.3647 - val_accuracy: 0.8370\n",
      "Epoch 4/500\n",
      "3734/3734 [==============================] - 5s 1ms/step - loss: 0.3655 - accuracy: 0.8367 - val_loss: 0.3647 - val_accuracy: 0.8371\n",
      "58334/58334 [==============================] - 52s 895us/step - loss: 0.3657 - accuracy: 0.8365\n",
      "Epoch 1/500\n",
      "3734/3734 [==============================] - 6s 1ms/step - loss: 0.3920 - accuracy: 0.8220 - val_loss: 0.3649 - val_accuracy: 0.8372\n",
      "Epoch 2/500\n",
      "3734/3734 [==============================] - 5s 1ms/step - loss: 0.3654 - accuracy: 0.8367 - val_loss: 0.3647 - val_accuracy: 0.8372\n",
      "Epoch 3/500\n",
      "3734/3734 [==============================] - 5s 1ms/step - loss: 0.3653 - accuracy: 0.8367 - val_loss: 0.3646 - val_accuracy: 0.8371\n",
      "Epoch 4/500\n",
      "3734/3734 [==============================] - 5s 1ms/step - loss: 0.3653 - accuracy: 0.8367 - val_loss: 0.3647 - val_accuracy: 0.8371\n",
      "Epoch 5/500\n",
      "3734/3734 [==============================] - 5s 1ms/step - loss: 0.3653 - accuracy: 0.8367 - val_loss: 0.3646 - val_accuracy: 0.8371\n",
      "Epoch 6/500\n",
      "3734/3734 [==============================] - 5s 1ms/step - loss: 0.3653 - accuracy: 0.8367 - val_loss: 0.3647 - val_accuracy: 0.8373\n",
      "58334/58334 [==============================] - 52s 885us/step - loss: 0.3659 - accuracy: 0.8366\n",
      "Epoch 1/500\n",
      "3734/3734 [==============================] - 7s 2ms/step - loss: 0.4234 - accuracy: 0.7948 - val_loss: 0.3238 - val_accuracy: 0.8485\n",
      "Epoch 2/500\n",
      "3734/3734 [==============================] - 6s 2ms/step - loss: 0.3527 - accuracy: 0.8377 - val_loss: 0.3187 - val_accuracy: 0.8518\n",
      "Epoch 3/500\n",
      "3734/3734 [==============================] - 6s 2ms/step - loss: 0.3518 - accuracy: 0.8374 - val_loss: 0.3186 - val_accuracy: 0.8513\n",
      "Epoch 4/500\n",
      "3734/3734 [==============================] - 6s 2ms/step - loss: 0.3518 - accuracy: 0.8371 - val_loss: 0.3186 - val_accuracy: 0.8519\n",
      "Epoch 5/500\n",
      "3734/3734 [==============================] - 6s 2ms/step - loss: 0.3517 - accuracy: 0.8374 - val_loss: 0.3188 - val_accuracy: 0.8519\n",
      "58334/58334 [==============================] - 53s 912us/step - loss: 0.3191 - accuracy: 0.8515\n",
      "Epoch 1/500\n",
      "3734/3734 [==============================] - 7s 2ms/step - loss: 0.4025 - accuracy: 0.7973 - val_loss: 0.3255 - val_accuracy: 0.8420\n",
      "Epoch 2/500\n",
      "3734/3734 [==============================] - 6s 2ms/step - loss: 0.3514 - accuracy: 0.8237 - val_loss: 0.3192 - val_accuracy: 0.8472\n",
      "Epoch 3/500\n",
      "3734/3734 [==============================] - 6s 2ms/step - loss: 0.3505 - accuracy: 0.8239 - val_loss: 0.3189 - val_accuracy: 0.8483\n",
      "Epoch 4/500\n",
      "3734/3734 [==============================] - 6s 2ms/step - loss: 0.3505 - accuracy: 0.8243 - val_loss: 0.3186 - val_accuracy: 0.8485\n",
      "Epoch 5/500\n",
      "3734/3734 [==============================] - 6s 2ms/step - loss: 0.3505 - accuracy: 0.8243 - val_loss: 0.3187 - val_accuracy: 0.8483\n",
      "Epoch 6/500\n",
      "3734/3734 [==============================] - 6s 2ms/step - loss: 0.3504 - accuracy: 0.8244 - val_loss: 0.3185 - val_accuracy: 0.8484\n",
      "Epoch 7/500\n",
      "3734/3734 [==============================] - 6s 2ms/step - loss: 0.3506 - accuracy: 0.8243 - val_loss: 0.3184 - val_accuracy: 0.8487\n",
      "58334/58334 [==============================] - 53s 906us/step - loss: 0.3193 - accuracy: 0.8479\n",
      "Epoch 1/500\n",
      "3734/3734 [==============================] - 7s 2ms/step - loss: 0.3835 - accuracy: 0.8220 - val_loss: 0.3222 - val_accuracy: 0.8483\n",
      "Epoch 2/500\n",
      "3734/3734 [==============================] - 6s 2ms/step - loss: 0.3536 - accuracy: 0.8373 - val_loss: 0.3202 - val_accuracy: 0.8494\n",
      "Epoch 3/500\n",
      "3734/3734 [==============================] - 6s 2ms/step - loss: 0.3521 - accuracy: 0.8382 - val_loss: 0.3190 - val_accuracy: 0.8507\n",
      "Epoch 4/500\n",
      "3734/3734 [==============================] - 6s 2ms/step - loss: 0.3515 - accuracy: 0.8381 - val_loss: 0.3184 - val_accuracy: 0.8515\n",
      "Epoch 5/500\n",
      "3734/3734 [==============================] - 6s 2ms/step - loss: 0.3512 - accuracy: 0.8378 - val_loss: 0.3188 - val_accuracy: 0.8520\n",
      "Epoch 6/500\n",
      "3734/3734 [==============================] - 6s 2ms/step - loss: 0.3513 - accuracy: 0.8377 - val_loss: 0.3185 - val_accuracy: 0.8518\n",
      "Epoch 7/500\n",
      "3734/3734 [==============================] - 6s 2ms/step - loss: 0.3514 - accuracy: 0.8376 - val_loss: 0.3185 - val_accuracy: 0.8516\n",
      "58334/58334 [==============================] - 53s 908us/step - loss: 0.3197 - accuracy: 0.8505\n",
      "Epoch 1/500\n",
      "3734/3734 [==============================] - 41s 11ms/step - loss: 0.2912 - accuracy: 0.8659 - val_loss: 0.2733 - val_accuracy: 0.8761\n",
      "Epoch 2/500\n",
      "3734/3734 [==============================] - 40s 11ms/step - loss: 0.2758 - accuracy: 0.8748 - val_loss: 0.2688 - val_accuracy: 0.8785\n",
      "Epoch 3/500\n",
      "3734/3734 [==============================] - 40s 11ms/step - loss: 0.2723 - accuracy: 0.8768 - val_loss: 0.2672 - val_accuracy: 0.8795\n",
      "Epoch 4/500\n",
      "3734/3734 [==============================] - 40s 11ms/step - loss: 0.2705 - accuracy: 0.8780 - val_loss: 0.2651 - val_accuracy: 0.8811\n",
      "Epoch 5/500\n",
      "3734/3734 [==============================] - 40s 11ms/step - loss: 0.2693 - accuracy: 0.8786 - val_loss: 0.2643 - val_accuracy: 0.8811\n",
      "Epoch 6/500\n",
      "3734/3734 [==============================] - 42s 11ms/step - loss: 0.2683 - accuracy: 0.8790 - val_loss: 0.2633 - val_accuracy: 0.8819\n",
      "Epoch 7/500\n",
      "3734/3734 [==============================] - 42s 11ms/step - loss: 0.2676 - accuracy: 0.8794 - val_loss: 0.2630 - val_accuracy: 0.8818\n",
      "Epoch 8/500\n",
      "3734/3734 [==============================] - 41s 11ms/step - loss: 0.2671 - accuracy: 0.8797 - val_loss: 0.2627 - val_accuracy: 0.8820\n",
      "Epoch 9/500\n",
      "3734/3734 [==============================] - 43s 11ms/step - loss: 0.2665 - accuracy: 0.8801 - val_loss: 0.2623 - val_accuracy: 0.8823\n",
      "Epoch 10/500\n",
      "3734/3734 [==============================] - 44s 12ms/step - loss: 0.2661 - accuracy: 0.8804 - val_loss: 0.2621 - val_accuracy: 0.8828\n",
      "Epoch 11/500\n",
      "3734/3734 [==============================] - 43s 12ms/step - loss: 0.2659 - accuracy: 0.8805 - val_loss: 0.2622 - val_accuracy: 0.8828\n",
      "Epoch 12/500\n",
      "3734/3734 [==============================] - 42s 11ms/step - loss: 0.2654 - accuracy: 0.8808 - val_loss: 0.2610 - val_accuracy: 0.8830\n",
      "Epoch 13/500\n",
      "3734/3734 [==============================] - 43s 11ms/step - loss: 0.2652 - accuracy: 0.8808 - val_loss: 0.2611 - val_accuracy: 0.8831\n",
      "Epoch 14/500\n",
      "3734/3734 [==============================] - 42s 11ms/step - loss: 0.2648 - accuracy: 0.8811 - val_loss: 0.2609 - val_accuracy: 0.8831\n",
      "Epoch 15/500\n",
      "3734/3734 [==============================] - 41s 11ms/step - loss: 0.2645 - accuracy: 0.8811 - val_loss: 0.2608 - val_accuracy: 0.8833\n",
      "Epoch 16/500\n",
      "3734/3734 [==============================] - 40s 11ms/step - loss: 0.2643 - accuracy: 0.8815 - val_loss: 0.2607 - val_accuracy: 0.8834\n",
      "Epoch 17/500\n",
      "3734/3734 [==============================] - 41s 11ms/step - loss: 0.2640 - accuracy: 0.8816 - val_loss: 0.2603 - val_accuracy: 0.8834\n",
      "Epoch 18/500\n",
      "3734/3734 [==============================] - 41s 11ms/step - loss: 0.2639 - accuracy: 0.8817 - val_loss: 0.2603 - val_accuracy: 0.8833\n",
      "Epoch 19/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3734/3734 [==============================] - 41s 11ms/step - loss: 0.2637 - accuracy: 0.8818 - val_loss: 0.2604 - val_accuracy: 0.8837\n",
      "Epoch 20/500\n",
      "3734/3734 [==============================] - 41s 11ms/step - loss: 0.2635 - accuracy: 0.8817 - val_loss: 0.2611 - val_accuracy: 0.8832\n",
      "58334/58334 [==============================] - 64s 1ms/step - loss: 0.2607 - accuracy: 0.8834\n",
      "Epoch 1/500\n",
      "3734/3734 [==============================] - 42s 11ms/step - loss: 0.2904 - accuracy: 0.8664 - val_loss: 0.2732 - val_accuracy: 0.8758\n",
      "Epoch 2/500\n",
      "3734/3734 [==============================] - 40s 11ms/step - loss: 0.2751 - accuracy: 0.8753 - val_loss: 0.2680 - val_accuracy: 0.8795\n",
      "Epoch 3/500\n",
      "3734/3734 [==============================] - 40s 11ms/step - loss: 0.2718 - accuracy: 0.8773 - val_loss: 0.2661 - val_accuracy: 0.8799\n",
      "Epoch 4/500\n",
      "3734/3734 [==============================] - 40s 11ms/step - loss: 0.2699 - accuracy: 0.8783 - val_loss: 0.2648 - val_accuracy: 0.8809\n",
      "Epoch 5/500\n",
      "3734/3734 [==============================] - 40s 11ms/step - loss: 0.2689 - accuracy: 0.8789 - val_loss: 0.2648 - val_accuracy: 0.8810\n",
      "Epoch 6/500\n",
      "3734/3734 [==============================] - 41s 11ms/step - loss: 0.2678 - accuracy: 0.8794 - val_loss: 0.2631 - val_accuracy: 0.8819\n",
      "Epoch 7/500\n",
      "3734/3734 [==============================] - 40s 11ms/step - loss: 0.2673 - accuracy: 0.8797 - val_loss: 0.2625 - val_accuracy: 0.8822\n",
      "Epoch 8/500\n",
      "3734/3734 [==============================] - 40s 11ms/step - loss: 0.2668 - accuracy: 0.8800 - val_loss: 0.2624 - val_accuracy: 0.8824\n",
      "Epoch 9/500\n",
      "3734/3734 [==============================] - 42s 11ms/step - loss: 0.2663 - accuracy: 0.8804 - val_loss: 0.2623 - val_accuracy: 0.8823\n",
      "Epoch 10/500\n",
      "3734/3734 [==============================] - 41s 11ms/step - loss: 0.2659 - accuracy: 0.8804 - val_loss: 0.2617 - val_accuracy: 0.8826\n",
      "Epoch 11/500\n",
      "3734/3734 [==============================] - 41s 11ms/step - loss: 0.2655 - accuracy: 0.8807 - val_loss: 0.2621 - val_accuracy: 0.8827\n",
      "Epoch 12/500\n",
      "3734/3734 [==============================] - 41s 11ms/step - loss: 0.2652 - accuracy: 0.8809 - val_loss: 0.2614 - val_accuracy: 0.8828\n",
      "Epoch 13/500\n",
      "3734/3734 [==============================] - 41s 11ms/step - loss: 0.2649 - accuracy: 0.8810 - val_loss: 0.2610 - val_accuracy: 0.8831\n",
      "Epoch 14/500\n",
      "3734/3734 [==============================] - 41s 11ms/step - loss: 0.2646 - accuracy: 0.8813 - val_loss: 0.2609 - val_accuracy: 0.8830\n",
      "Epoch 15/500\n",
      "3734/3734 [==============================] - 41s 11ms/step - loss: 0.2644 - accuracy: 0.8813 - val_loss: 0.2619 - val_accuracy: 0.8830\n",
      "Epoch 16/500\n",
      "3734/3734 [==============================] - 41s 11ms/step - loss: 0.2642 - accuracy: 0.8814 - val_loss: 0.2609 - val_accuracy: 0.8831\n",
      "58334/58334 [==============================] - 65s 1ms/step - loss: 0.2611 - accuracy: 0.8827\n",
      "Epoch 1/500\n",
      "3734/3734 [==============================] - 43s 11ms/step - loss: 0.2907 - accuracy: 0.8663 - val_loss: 0.2738 - val_accuracy: 0.8758\n",
      "Epoch 2/500\n",
      "3734/3734 [==============================] - 47s 13ms/step - loss: 0.2752 - accuracy: 0.8752 - val_loss: 0.2685 - val_accuracy: 0.8786\n",
      "Epoch 3/500\n",
      "3734/3734 [==============================] - 47s 13ms/step - loss: 0.2717 - accuracy: 0.8772 - val_loss: 0.2688 - val_accuracy: 0.8791\n",
      "Epoch 4/500\n",
      "3734/3734 [==============================] - 49s 13ms/step - loss: 0.2699 - accuracy: 0.8783 - val_loss: 0.2646 - val_accuracy: 0.8810\n",
      "Epoch 5/500\n",
      "3734/3734 [==============================] - 49s 13ms/step - loss: 0.2687 - accuracy: 0.8789 - val_loss: 0.2655 - val_accuracy: 0.8805\n",
      "Epoch 6/500\n",
      "3734/3734 [==============================] - 48s 13ms/step - loss: 0.2679 - accuracy: 0.8793 - val_loss: 0.2634 - val_accuracy: 0.8819\n",
      "Epoch 7/500\n",
      "3734/3734 [==============================] - 48s 13ms/step - loss: 0.2673 - accuracy: 0.8797 - val_loss: 0.2629 - val_accuracy: 0.8821\n",
      "Epoch 8/500\n",
      "3734/3734 [==============================] - 47s 13ms/step - loss: 0.2668 - accuracy: 0.8798 - val_loss: 0.2626 - val_accuracy: 0.8821\n",
      "Epoch 9/500\n",
      "3734/3734 [==============================] - 47s 13ms/step - loss: 0.2661 - accuracy: 0.8803 - val_loss: 0.2625 - val_accuracy: 0.8824\n",
      "Epoch 10/500\n",
      "3734/3734 [==============================] - 47s 13ms/step - loss: 0.2657 - accuracy: 0.8807 - val_loss: 0.2623 - val_accuracy: 0.8825\n",
      "Epoch 11/500\n",
      "3734/3734 [==============================] - 48s 13ms/step - loss: 0.2654 - accuracy: 0.8809 - val_loss: 0.2616 - val_accuracy: 0.8825\n",
      "Epoch 12/500\n",
      "3734/3734 [==============================] - 48s 13ms/step - loss: 0.2651 - accuracy: 0.8809 - val_loss: 0.2617 - val_accuracy: 0.8828\n",
      "Epoch 13/500\n",
      "3734/3734 [==============================] - 47s 13ms/step - loss: 0.2646 - accuracy: 0.8812 - val_loss: 0.2611 - val_accuracy: 0.8830\n",
      "Epoch 14/500\n",
      "3734/3734 [==============================] - 48s 13ms/step - loss: 0.2645 - accuracy: 0.8812 - val_loss: 0.2612 - val_accuracy: 0.8828\n",
      "Epoch 15/500\n",
      "3734/3734 [==============================] - 48s 13ms/step - loss: 0.2642 - accuracy: 0.8814 - val_loss: 0.2605 - val_accuracy: 0.8832\n",
      "Epoch 16/500\n",
      "3734/3734 [==============================] - 48s 13ms/step - loss: 0.2639 - accuracy: 0.8817 - val_loss: 0.2611 - val_accuracy: 0.8830\n",
      "Epoch 17/500\n",
      "3734/3734 [==============================] - 47s 13ms/step - loss: 0.2637 - accuracy: 0.8818 - val_loss: 0.2605 - val_accuracy: 0.8833\n",
      "Epoch 18/500\n",
      "3734/3734 [==============================] - 47s 13ms/step - loss: 0.2637 - accuracy: 0.8817 - val_loss: 0.2604 - val_accuracy: 0.8833\n",
      "58334/58334 [==============================] - 70s 1ms/step - loss: 0.2611 - accuracy: 0.8827\n",
      "Epoch 1/500\n",
      "3734/3734 [==============================] - 23s 6ms/step - loss: 0.3046 - accuracy: 0.8586 - val_loss: 0.2810 - val_accuracy: 0.8724\n",
      "Epoch 2/500\n",
      "3734/3734 [==============================] - 22s 6ms/step - loss: 0.2856 - accuracy: 0.8696 - val_loss: 0.2747 - val_accuracy: 0.8758\n",
      "Epoch 3/500\n",
      "3734/3734 [==============================] - 22s 6ms/step - loss: 0.2816 - accuracy: 0.8722 - val_loss: 0.2716 - val_accuracy: 0.8777\n",
      "Epoch 4/500\n",
      "3734/3734 [==============================] - 21s 6ms/step - loss: 0.2796 - accuracy: 0.8735 - val_loss: 0.2713 - val_accuracy: 0.8782\n",
      "Epoch 5/500\n",
      "3734/3734 [==============================] - 22s 6ms/step - loss: 0.2784 - accuracy: 0.8741 - val_loss: 0.2694 - val_accuracy: 0.8787\n",
      "Epoch 6/500\n",
      "3734/3734 [==============================] - 23s 6ms/step - loss: 0.2775 - accuracy: 0.8746 - val_loss: 0.2702 - val_accuracy: 0.8789\n",
      "Epoch 7/500\n",
      "3734/3734 [==============================] - 22s 6ms/step - loss: 0.2769 - accuracy: 0.8749 - val_loss: 0.2694 - val_accuracy: 0.8789\n",
      "Epoch 8/500\n",
      "3734/3734 [==============================] - 22s 6ms/step - loss: 0.2764 - accuracy: 0.8752 - val_loss: 0.2693 - val_accuracy: 0.8794\n",
      "58334/58334 [==============================] - 56s 966us/step - loss: 0.2691 - accuracy: 0.8796\n",
      "Epoch 1/500\n",
      "3734/3734 [==============================] - 21s 5ms/step - loss: 0.3042 - accuracy: 0.8587 - val_loss: 0.2809 - val_accuracy: 0.8719\n",
      "Epoch 2/500\n",
      "3734/3734 [==============================] - 21s 6ms/step - loss: 0.2855 - accuracy: 0.8697 - val_loss: 0.2751 - val_accuracy: 0.8754\n",
      "Epoch 3/500\n",
      "3734/3734 [==============================] - 21s 6ms/step - loss: 0.2813 - accuracy: 0.8723 - val_loss: 0.2725 - val_accuracy: 0.8775\n",
      "Epoch 4/500\n",
      "3734/3734 [==============================] - 22s 6ms/step - loss: 0.2791 - accuracy: 0.8736 - val_loss: 0.2725 - val_accuracy: 0.8778\n",
      "Epoch 5/500\n",
      "3734/3734 [==============================] - 22s 6ms/step - loss: 0.2778 - accuracy: 0.8743 - val_loss: 0.2698 - val_accuracy: 0.8788\n",
      "Epoch 6/500\n",
      "3734/3734 [==============================] - 22s 6ms/step - loss: 0.2768 - accuracy: 0.8750 - val_loss: 0.2701 - val_accuracy: 0.8792\n",
      "Epoch 7/500\n",
      "3734/3734 [==============================] - 22s 6ms/step - loss: 0.2763 - accuracy: 0.8754 - val_loss: 0.2696 - val_accuracy: 0.8794\n",
      "Epoch 8/500\n",
      "3734/3734 [==============================] - 22s 6ms/step - loss: 0.2757 - accuracy: 0.8756 - val_loss: 0.2694 - val_accuracy: 0.8794\n",
      "Epoch 9/500\n",
      "3734/3734 [==============================] - 21s 6ms/step - loss: 0.2753 - accuracy: 0.8759 - val_loss: 0.2701 - val_accuracy: 0.8798\n",
      "Epoch 10/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3734/3734 [==============================] - 21s 6ms/step - loss: 0.2749 - accuracy: 0.8760 - val_loss: 0.2707 - val_accuracy: 0.8799\n",
      "Epoch 11/500\n",
      "3734/3734 [==============================] - 22s 6ms/step - loss: 0.2745 - accuracy: 0.8762 - val_loss: 0.2714 - val_accuracy: 0.8798\n",
      "58334/58334 [==============================] - 54s 930us/step - loss: 0.2716 - accuracy: 0.8797\n",
      "Epoch 1/500\n",
      "3734/3734 [==============================] - 23s 6ms/step - loss: 0.3035 - accuracy: 0.8591 - val_loss: 0.2799 - val_accuracy: 0.8730\n",
      "Epoch 2/500\n",
      "3734/3734 [==============================] - 22s 6ms/step - loss: 0.2844 - accuracy: 0.8702 - val_loss: 0.2733 - val_accuracy: 0.8766\n",
      "Epoch 3/500\n",
      "3734/3734 [==============================] - 21s 6ms/step - loss: 0.2808 - accuracy: 0.8725 - val_loss: 0.2714 - val_accuracy: 0.8778\n",
      "Epoch 4/500\n",
      "3734/3734 [==============================] - 21s 6ms/step - loss: 0.2789 - accuracy: 0.8737 - val_loss: 0.2700 - val_accuracy: 0.8785\n",
      "Epoch 5/500\n",
      "3734/3734 [==============================] - 22s 6ms/step - loss: 0.2775 - accuracy: 0.8746 - val_loss: 0.2697 - val_accuracy: 0.8787\n",
      "Epoch 6/500\n",
      "3734/3734 [==============================] - 22s 6ms/step - loss: 0.2768 - accuracy: 0.8749 - val_loss: 0.2698 - val_accuracy: 0.8791\n",
      "Epoch 7/500\n",
      "3734/3734 [==============================] - 22s 6ms/step - loss: 0.2762 - accuracy: 0.8752 - val_loss: 0.2692 - val_accuracy: 0.8791\n",
      "Epoch 8/500\n",
      "3734/3734 [==============================] - 22s 6ms/step - loss: 0.2756 - accuracy: 0.8755 - val_loss: 0.2680 - val_accuracy: 0.8798\n",
      "Epoch 9/500\n",
      "3734/3734 [==============================] - 22s 6ms/step - loss: 0.2753 - accuracy: 0.8758 - val_loss: 0.2702 - val_accuracy: 0.8799\n",
      "Epoch 10/500\n",
      "3734/3734 [==============================] - 22s 6ms/step - loss: 0.2748 - accuracy: 0.8761 - val_loss: 0.2695 - val_accuracy: 0.8801\n",
      "Epoch 11/500\n",
      "3734/3734 [==============================] - 22s 6ms/step - loss: 0.2745 - accuracy: 0.8763 - val_loss: 0.2681 - val_accuracy: 0.8804\n",
      "58334/58334 [==============================] - 56s 959us/step - loss: 0.2688 - accuracy: 0.8797\n",
      "Epoch 1/500\n",
      "3734/3734 [==============================] - 26s 7ms/step - loss: 0.3035 - accuracy: 0.8592 - val_loss: 0.2873 - val_accuracy: 0.8668\n",
      "Epoch 2/500\n",
      "3734/3734 [==============================] - 27s 7ms/step - loss: 0.2883 - accuracy: 0.8669 - val_loss: 0.2822 - val_accuracy: 0.8705\n",
      "Epoch 3/500\n",
      "3734/3734 [==============================] - 27s 7ms/step - loss: 0.2849 - accuracy: 0.8693 - val_loss: 0.2788 - val_accuracy: 0.8727\n",
      "Epoch 4/500\n",
      "3734/3734 [==============================] - 28s 7ms/step - loss: 0.2823 - accuracy: 0.8708 - val_loss: 0.2770 - val_accuracy: 0.8740\n",
      "Epoch 5/500\n",
      "3734/3734 [==============================] - 26s 7ms/step - loss: 0.2809 - accuracy: 0.8717 - val_loss: 0.2756 - val_accuracy: 0.8744\n",
      "Epoch 6/500\n",
      "3734/3734 [==============================] - 28s 7ms/step - loss: 0.2800 - accuracy: 0.8724 - val_loss: 0.2750 - val_accuracy: 0.8751\n",
      "Epoch 7/500\n",
      "3734/3734 [==============================] - 28s 7ms/step - loss: 0.2794 - accuracy: 0.8726 - val_loss: 0.2745 - val_accuracy: 0.8755\n",
      "Epoch 8/500\n",
      "3734/3734 [==============================] - 26s 7ms/step - loss: 0.2790 - accuracy: 0.8729 - val_loss: 0.2738 - val_accuracy: 0.8760\n",
      "Epoch 9/500\n",
      "3734/3734 [==============================] - 28s 8ms/step - loss: 0.2787 - accuracy: 0.8732 - val_loss: 0.2737 - val_accuracy: 0.8758\n",
      "Epoch 10/500\n",
      "3734/3734 [==============================] - 27s 7ms/step - loss: 0.2784 - accuracy: 0.8732 - val_loss: 0.2739 - val_accuracy: 0.8757\n",
      "Epoch 11/500\n",
      "3734/3734 [==============================] - 28s 7ms/step - loss: 0.2782 - accuracy: 0.8735 - val_loss: 0.2731 - val_accuracy: 0.8765\n",
      "Epoch 12/500\n",
      "3734/3734 [==============================] - 27s 7ms/step - loss: 0.2780 - accuracy: 0.8736 - val_loss: 0.2734 - val_accuracy: 0.8758\n",
      "Epoch 13/500\n",
      "3734/3734 [==============================] - 28s 8ms/step - loss: 0.2778 - accuracy: 0.8736 - val_loss: 0.2729 - val_accuracy: 0.8761\n",
      "Epoch 14/500\n",
      "3734/3734 [==============================] - 28s 7ms/step - loss: 0.2777 - accuracy: 0.8738 - val_loss: 0.2726 - val_accuracy: 0.8764\n",
      "Epoch 15/500\n",
      "3734/3734 [==============================] - 29s 8ms/step - loss: 0.2775 - accuracy: 0.8739 - val_loss: 0.2731 - val_accuracy: 0.8763\n",
      "Epoch 16/500\n",
      "3734/3734 [==============================] - 27s 7ms/step - loss: 0.2774 - accuracy: 0.8739 - val_loss: 0.2725 - val_accuracy: 0.8764\n",
      "Epoch 17/500\n",
      "3734/3734 [==============================] - 28s 8ms/step - loss: 0.2772 - accuracy: 0.8741 - val_loss: 0.2726 - val_accuracy: 0.8763\n",
      "58334/58334 [==============================] - 56s 955us/step - loss: 0.2727 - accuracy: 0.8763\n",
      "Epoch 1/500\n",
      "3734/3734 [==============================] - 30s 8ms/step - loss: 0.3031 - accuracy: 0.8596 - val_loss: 0.2870 - val_accuracy: 0.8669\n",
      "Epoch 2/500\n",
      "3734/3734 [==============================] - 27s 7ms/step - loss: 0.2882 - accuracy: 0.8668 - val_loss: 0.2814 - val_accuracy: 0.8710\n",
      "Epoch 3/500\n",
      "3734/3734 [==============================] - 28s 7ms/step - loss: 0.2848 - accuracy: 0.8692 - val_loss: 0.2793 - val_accuracy: 0.8724\n",
      "Epoch 4/500\n",
      "3734/3734 [==============================] - 27s 7ms/step - loss: 0.2829 - accuracy: 0.8705 - val_loss: 0.2775 - val_accuracy: 0.8735\n",
      "Epoch 5/500\n",
      "3734/3734 [==============================] - 29s 8ms/step - loss: 0.2814 - accuracy: 0.8715 - val_loss: 0.2761 - val_accuracy: 0.8744\n",
      "Epoch 6/500\n",
      "3734/3734 [==============================] - 28s 8ms/step - loss: 0.2804 - accuracy: 0.8721 - val_loss: 0.2754 - val_accuracy: 0.8748\n",
      "Epoch 7/500\n",
      "3734/3734 [==============================] - 27s 7ms/step - loss: 0.2798 - accuracy: 0.8725 - val_loss: 0.2749 - val_accuracy: 0.8751\n",
      "Epoch 8/500\n",
      "3734/3734 [==============================] - 29s 8ms/step - loss: 0.2794 - accuracy: 0.8727 - val_loss: 0.2743 - val_accuracy: 0.8757\n",
      "Epoch 9/500\n",
      "3734/3734 [==============================] - 30s 8ms/step - loss: 0.2791 - accuracy: 0.8728 - val_loss: 0.2745 - val_accuracy: 0.8755\n",
      "Epoch 10/500\n",
      "3734/3734 [==============================] - 28s 8ms/step - loss: 0.2787 - accuracy: 0.8732 - val_loss: 0.2746 - val_accuracy: 0.8755\n",
      "Epoch 11/500\n",
      "3734/3734 [==============================] - 29s 8ms/step - loss: 0.2785 - accuracy: 0.8733 - val_loss: 0.2739 - val_accuracy: 0.8759\n",
      "Epoch 12/500\n",
      "3734/3734 [==============================] - 29s 8ms/step - loss: 0.2783 - accuracy: 0.8735 - val_loss: 0.2735 - val_accuracy: 0.8757\n",
      "Epoch 13/500\n",
      "3734/3734 [==============================] - 28s 8ms/step - loss: 0.2781 - accuracy: 0.8735 - val_loss: 0.2734 - val_accuracy: 0.8760\n",
      "Epoch 14/500\n",
      "3734/3734 [==============================] - 29s 8ms/step - loss: 0.2779 - accuracy: 0.8736 - val_loss: 0.2731 - val_accuracy: 0.8761\n",
      "Epoch 15/500\n",
      "3734/3734 [==============================] - 29s 8ms/step - loss: 0.2778 - accuracy: 0.8737 - val_loss: 0.2732 - val_accuracy: 0.8762\n",
      "Epoch 16/500\n",
      "3734/3734 [==============================] - 28s 8ms/step - loss: 0.2777 - accuracy: 0.8737 - val_loss: 0.2729 - val_accuracy: 0.8761\n",
      "Epoch 17/500\n",
      "3734/3734 [==============================] - 29s 8ms/step - loss: 0.2775 - accuracy: 0.8738 - val_loss: 0.2730 - val_accuracy: 0.8764\n",
      "Epoch 18/500\n",
      "3734/3734 [==============================] - 29s 8ms/step - loss: 0.2776 - accuracy: 0.8738 - val_loss: 0.2723 - val_accuracy: 0.8765\n",
      "Epoch 19/500\n",
      "3734/3734 [==============================] - 28s 8ms/step - loss: 0.2773 - accuracy: 0.8739 - val_loss: 0.2726 - val_accuracy: 0.8761\n",
      "Epoch 20/500\n",
      "3734/3734 [==============================] - 30s 8ms/step - loss: 0.2773 - accuracy: 0.8740 - val_loss: 0.2729 - val_accuracy: 0.8766\n",
      "Epoch 21/500\n",
      "3734/3734 [==============================] - 28s 8ms/step - loss: 0.2772 - accuracy: 0.8740 - val_loss: 0.2729 - val_accuracy: 0.8763\n",
      "58334/58334 [==============================] - 56s 955us/step - loss: 0.2733 - accuracy: 0.8761\n",
      "Epoch 1/500\n",
      "3734/3734 [==============================] - 31s 8ms/step - loss: 0.3032 - accuracy: 0.8596 - val_loss: 0.2867 - val_accuracy: 0.8674\n",
      "Epoch 2/500\n",
      "3734/3734 [==============================] - 30s 8ms/step - loss: 0.2883 - accuracy: 0.8669 - val_loss: 0.2823 - val_accuracy: 0.8703\n",
      "Epoch 3/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3734/3734 [==============================] - 31s 8ms/step - loss: 0.2846 - accuracy: 0.8693 - val_loss: 0.2787 - val_accuracy: 0.8728\n",
      "Epoch 4/500\n",
      "3734/3734 [==============================] - 30s 8ms/step - loss: 0.2824 - accuracy: 0.8709 - val_loss: 0.2767 - val_accuracy: 0.8740\n",
      "Epoch 5/500\n",
      "3734/3734 [==============================] - 30s 8ms/step - loss: 0.2810 - accuracy: 0.8718 - val_loss: 0.2763 - val_accuracy: 0.8742\n",
      "Epoch 6/500\n",
      "3734/3734 [==============================] - 30s 8ms/step - loss: 0.2802 - accuracy: 0.8723 - val_loss: 0.2751 - val_accuracy: 0.8750\n",
      "Epoch 7/500\n",
      "3734/3734 [==============================] - 31s 8ms/step - loss: 0.2796 - accuracy: 0.8727 - val_loss: 0.2744 - val_accuracy: 0.8752\n",
      "Epoch 8/500\n",
      "3734/3734 [==============================] - 34s 9ms/step - loss: 0.2791 - accuracy: 0.8730 - val_loss: 0.2741 - val_accuracy: 0.8756\n",
      "Epoch 9/500\n",
      "3734/3734 [==============================] - 32s 9ms/step - loss: 0.2788 - accuracy: 0.8730 - val_loss: 0.2738 - val_accuracy: 0.8758\n",
      "Epoch 10/500\n",
      "3734/3734 [==============================] - 32s 9ms/step - loss: 0.2786 - accuracy: 0.8733 - val_loss: 0.2738 - val_accuracy: 0.8756\n",
      "Epoch 11/500\n",
      "3734/3734 [==============================] - 32s 8ms/step - loss: 0.2784 - accuracy: 0.8733 - val_loss: 0.2737 - val_accuracy: 0.8758\n",
      "Epoch 12/500\n",
      "3734/3734 [==============================] - 32s 8ms/step - loss: 0.2780 - accuracy: 0.8736 - val_loss: 0.2733 - val_accuracy: 0.8761\n",
      "Epoch 13/500\n",
      "3734/3734 [==============================] - 30s 8ms/step - loss: 0.2779 - accuracy: 0.8737 - val_loss: 0.2735 - val_accuracy: 0.8757\n",
      "Epoch 14/500\n",
      "3734/3734 [==============================] - 31s 8ms/step - loss: 0.2776 - accuracy: 0.8739 - val_loss: 0.2729 - val_accuracy: 0.8762\n",
      "Epoch 15/500\n",
      "3734/3734 [==============================] - 31s 8ms/step - loss: 0.2777 - accuracy: 0.8738 - val_loss: 0.2734 - val_accuracy: 0.8759\n",
      "Epoch 16/500\n",
      "3734/3734 [==============================] - 31s 8ms/step - loss: 0.2775 - accuracy: 0.8738 - val_loss: 0.2727 - val_accuracy: 0.8765\n",
      "Epoch 17/500\n",
      "3734/3734 [==============================] - 31s 8ms/step - loss: 0.2773 - accuracy: 0.8740 - val_loss: 0.2727 - val_accuracy: 0.8763\n",
      "58334/58334 [==============================] - 59s 1ms/step - loss: 0.2736 - accuracy: 0.8756\n",
      "Epoch 1/500\n",
      "5600/5600 [==============================] - 77s 14ms/step - loss: 0.2862 - accuracy: 0.8687 - val_loss: 0.2710 - val_accuracy: 0.8772\n",
      "Epoch 2/500\n",
      "5600/5600 [==============================] - 77s 14ms/step - loss: 0.2731 - accuracy: 0.8764 - val_loss: 0.2665 - val_accuracy: 0.8798\n",
      "Epoch 3/500\n",
      "5600/5600 [==============================] - 79s 14ms/step - loss: 0.2702 - accuracy: 0.8782 - val_loss: 0.2645 - val_accuracy: 0.8812\n",
      "Epoch 4/500\n",
      "5600/5600 [==============================] - 68s 12ms/step - loss: 0.2686 - accuracy: 0.8790 - val_loss: 0.2635 - val_accuracy: 0.8818\n",
      "Epoch 5/500\n",
      "5600/5600 [==============================] - 72s 13ms/step - loss: 0.2675 - accuracy: 0.8796 - val_loss: 0.2625 - val_accuracy: 0.8822\n",
      "Epoch 6/500\n",
      "5600/5600 [==============================] - 71s 13ms/step - loss: 0.2668 - accuracy: 0.8800 - val_loss: 0.2622 - val_accuracy: 0.8824\n",
      "Epoch 7/500\n",
      "5600/5600 [==============================] - 71s 13ms/step - loss: 0.2662 - accuracy: 0.8803 - val_loss: 0.2615 - val_accuracy: 0.8826\n",
      "Epoch 8/500\n",
      "5600/5600 [==============================] - 72s 13ms/step - loss: 0.2658 - accuracy: 0.8806 - val_loss: 0.2613 - val_accuracy: 0.8830\n",
      "Epoch 9/500\n",
      "5600/5600 [==============================] - 72s 13ms/step - loss: 0.2654 - accuracy: 0.8808 - val_loss: 0.2605 - val_accuracy: 0.8832\n",
      "Epoch 10/500\n",
      "5600/5600 [==============================] - 73s 13ms/step - loss: 0.2649 - accuracy: 0.8811 - val_loss: 0.2607 - val_accuracy: 0.8832\n",
      "Epoch 11/500\n",
      "5600/5600 [==============================] - 73s 13ms/step - loss: 0.2647 - accuracy: 0.8812 - val_loss: 0.2600 - val_accuracy: 0.8837\n",
      "Epoch 12/500\n",
      "5600/5600 [==============================] - 72s 13ms/step - loss: 0.2644 - accuracy: 0.8813 - val_loss: 0.2602 - val_accuracy: 0.8835\n",
      "Epoch 13/500\n",
      "5600/5600 [==============================] - 71s 13ms/step - loss: 0.2641 - accuracy: 0.8815 - val_loss: 0.2601 - val_accuracy: 0.8835\n",
      "Epoch 14/500\n",
      "5600/5600 [==============================] - 71s 13ms/step - loss: 0.2638 - accuracy: 0.8817 - val_loss: 0.2595 - val_accuracy: 0.8840\n",
      "Epoch 15/500\n",
      "5600/5600 [==============================] - 73s 13ms/step - loss: 0.2637 - accuracy: 0.8818 - val_loss: 0.2602 - val_accuracy: 0.8836\n",
      "Epoch 16/500\n",
      "5600/5600 [==============================] - 73s 13ms/step - loss: 0.2635 - accuracy: 0.8819 - val_loss: 0.2598 - val_accuracy: 0.8837\n",
      "Epoch 17/500\n",
      "5600/5600 [==============================] - 72s 13ms/step - loss: 0.2633 - accuracy: 0.8820 - val_loss: 0.2593 - val_accuracy: 0.8839\n",
      "Epoch 18/500\n",
      "5600/5600 [==============================] - 72s 13ms/step - loss: 0.2631 - accuracy: 0.8821 - val_loss: 0.2599 - val_accuracy: 0.8841\n",
      "Epoch 19/500\n",
      "5600/5600 [==============================] - 72s 13ms/step - loss: 0.2630 - accuracy: 0.8821 - val_loss: 0.2591 - val_accuracy: 0.8839\n",
      "Epoch 20/500\n",
      "5600/5600 [==============================] - 74s 13ms/step - loss: 0.2628 - accuracy: 0.8821 - val_loss: 0.2592 - val_accuracy: 0.8841\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=3,\n",
       "                   estimator=&lt;keras.wrappers.scikit_learn.KerasRegressor object at 0x000001F24E042610&gt;,\n",
       "                   n_iter=5,\n",
       "                   param_distributions={&#x27;num_hidden_layers&#x27;: [0, 1, 2, 3],\n",
       "                                        &#x27;num_neurons&#x27;: array([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
       "        14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n",
       "        27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n",
       "        40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
       "        53,  54,  55,  56,  57,  58...\n",
       "       404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416,\n",
       "       417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429,\n",
       "       430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442,\n",
       "       443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455,\n",
       "       456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468,\n",
       "       469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
       "       482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494,\n",
       "       495, 496, 497, 498, 499])})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=3,\n",
       "                   estimator=&lt;keras.wrappers.scikit_learn.KerasRegressor object at 0x000001F24E042610&gt;,\n",
       "                   n_iter=5,\n",
       "                   param_distributions={&#x27;num_hidden_layers&#x27;: [0, 1, 2, 3],\n",
       "                                        &#x27;num_neurons&#x27;: array([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
       "        14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n",
       "        27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n",
       "        40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
       "        53,  54,  55,  56,  57,  58...\n",
       "       404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416,\n",
       "       417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429,\n",
       "       430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442,\n",
       "       443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455,\n",
       "       456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468,\n",
       "       469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
       "       482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494,\n",
       "       495, 496, 497, 498, 499])})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: KerasRegressor</label><div class=\"sk-toggleable__content\"><pre>&lt;keras.wrappers.scikit_learn.KerasRegressor object at 0x000001F24E042610&gt;</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KerasRegressor</label><div class=\"sk-toggleable__content\"><pre>&lt;keras.wrappers.scikit_learn.KerasRegressor object at 0x000001F24E042610&gt;</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=<keras.wrappers.scikit_learn.KerasRegressor object at 0x000001F24E042610>,\n",
       "                   n_iter=5,\n",
       "                   param_distributions={'num_hidden_layers': [0, 1, 2, 3],\n",
       "                                        'num_neurons': array([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
       "        14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n",
       "        27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n",
       "        40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
       "        53,  54,  55,  56,  57,  58...\n",
       "       404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416,\n",
       "       417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429,\n",
       "       430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442,\n",
       "       443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455,\n",
       "       456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468,\n",
       "       469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
       "       482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494,\n",
       "       495, 496, 497, 498, 499])})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_root = os.path.join(os.curdir, \"my_training_logs\")\n",
    "\n",
    "def get_log_dir():\n",
    "    import time\n",
    "    timestamp = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(log_root, timestamp)\n",
    "\n",
    "log_dir = get_log_dir()\n",
    "\n",
    "# # Print current working directory and log directory\n",
    "# print(os.getcwd())\n",
    "# print(log_dir)\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir)\n",
    "\n",
    "def create_model(num_hidden_layers=1, num_neurons=30, learning_rate=3e-3, input_shape=[28]):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for layer in range(num_hidden_layers):\n",
    "        model.add(tf.keras.layers.Dense(num_neurons, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.Dropout(.2, input_shape=(2,)))\n",
    "    model.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "    optimizer = tf.keras.optimizers.Adam()\n",
    "    loss = tf.keras.losses.BinaryCrossentropy()\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "regressor = tf.keras.wrappers.scikit_learn.KerasRegressor(create_model)\n",
    "\n",
    "param_distributions = {\n",
    "    \"num_hidden_layers\": [0, 1, 2, 3],\n",
    "    \"num_neurons\": np.arange(1, 500)\n",
    "}\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3, min_delta=2e-4)\n",
    "\n",
    "random_search_cv = RandomizedSearchCV(regressor, param_distributions, n_iter=5, cv=3)\n",
    "random_search_cv.fit(X_train, y_train, epochs=500,\n",
    "                      validation_data=(X_test, y_test),\n",
    "                      callbacks=[tensorboard_callback, early_stop], batch_size=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fada3818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_neurons': 343, 'num_hidden_layers': 2}\n",
      "-0.2609912157058716\n"
     ]
    }
   ],
   "source": [
    "print(random_search_cv.best_params_)\n",
    "print(random_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be84e98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
