{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0354002",
   "metadata": {},
   "source": [
    "# DS7333 Case Study \n",
    "##  Naive Bayes and Clustering\n",
    "\n",
    "#### John Girard, Shijo Joseph, Douglas Yip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7fc787",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext pycodestyle_magic\n",
    "%pycodestyle_on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83abe01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import email\n",
    "from bs4 import BeautifulSoup as BS4\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b6d7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "dir_count = 0\n",
    "for root_dir, cur_dir, files in os.walk(\".\\\\SpamAssassinMessages\"):\n",
    "    dir_count = len(files)\n",
    "    count += len(files)\n",
    "    for names in cur_dir:\n",
    "        print(names, len(os.listdir(os.path.join(root_dir, names))))\n",
    "print('Total Files:', count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9e0c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(\".\\\\SpamAssassinMessages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c621c957",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = []\n",
    "contents = []\n",
    "types = []\n",
    "labels = []\n",
    "labelnames = []\n",
    "message = ''\n",
    "\n",
    "for root, dirs, files in os.walk(\".\\\\SpamAssassinMessages\"):\n",
    "    for name in files:\n",
    "        with open(os.path.join(root, name),\n",
    "                  'r', encoding='latin1') as f:\n",
    "            message = ''\n",
    "            try:\n",
    "                x = email.message_from_file(f)\n",
    "            except UnicodeDecodeError:\n",
    "                print(\"Error in file: Unknown Error\")\n",
    "            if \"multipart\" in x.get_content_type():\n",
    "                if x.is_multipart():\n",
    "                    for part in x.get_payload():\n",
    "                        if \"text/plain\" in part.get_content_type():\n",
    "                            message = message + \\\n",
    "                                (part.get_payload()\n",
    "                                 .replace(\"\\t\", \"\")\n",
    "                                 .replace(\"\\n\", \" \")\n",
    "                                 .replace(\"^https?://\", ' ')\n",
    "                                 .replace(\"^http?://\", ' ')\n",
    "                                 .replace(\"-\", \" \"))\n",
    "                        elif \"text/html\" in part.get_content_type():\n",
    "                            message = message + (\n",
    "                                BS4(part.get_payload())\n",
    "                                .get_text()\n",
    "                                .replace(\"\\t\", \"\")\n",
    "                                .replace(\"^https?://\", ' ')\n",
    "                                .replace(\"^http?://\", ' ')\n",
    "                                .replace(\"\\n\", \" \")\n",
    "                                .replace(\"-\", \" \"))\n",
    "                contents.append(message.replace(\"\\n\", \" \")\n",
    "                                .replace(\"\\t\", \"\")\n",
    "                                .replace(\"^https?://\", ' ')\n",
    "                                .replace(\"^http?://\", ' ')\n",
    "                                .replace(\"-\", \" \"))\n",
    "            elif \"text/plain\" in x.get_content_type():\n",
    "                contents.append(x.get_payload()\n",
    "                                .replace(\"\\t\", \"\")\n",
    "                                .replace(\"\\n\", \" \")\n",
    "                                .replace(\"^https?://\", ' ')\n",
    "                                .replace(\"^http?://\", ' ')\n",
    "                                .replace(\"-\", \" \"))\n",
    "            elif \"text/html\" in x.get_content_type():\n",
    "                contents.append(BS4(x.get_payload())\n",
    "                                .get_text()\n",
    "                                .replace(\"\\t\", \"\")\n",
    "                                .replace(\"^https?://\", ' ')\n",
    "                                .replace(\"^http?://\", ' ')\n",
    "                                .replace(\"\\n\", \" \")\n",
    "                                .replace(\"-\", \" \"))\n",
    "            types.append(x.get_content_type())\n",
    "            if \"ham\" in root:\n",
    "                labelnames.append('ham')\n",
    "                labels.append(1)\n",
    "            elif \"spam\" in root:\n",
    "                labelnames.append('spam')\n",
    "                labels.append(0)\n",
    "            file_name.append(os.path.join(root, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c204450",
   "metadata": {},
   "outputs": [],
   "source": [
    "types = pd.DataFrame(types)\n",
    "types.shape\n",
    "types.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30d4876",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NB = pd.DataFrame()\n",
    "df_NB['Filename'] = file_name\n",
    "df_NB['types'] = types\n",
    "df_NB['email_body'] = contents\n",
    "df_NB['labelnames'] = labelnames\n",
    "df_NB['labels'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc226ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d36f64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8aa4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "the_count = CountVectorizer()\n",
    "Xtrain = the_count.fit_transform(df_NB['email_body'])\n",
    "Xtrain = Xtrain.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aebc849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate distortion for a range of number of cluster\n",
    "distortions = []\n",
    "best_distortion = 1e12\n",
    "best_i = 10\n",
    "for i in range(1, 30):\n",
    "    km = KMeans(n_clusters=i,\n",
    "                n_init='auto',\n",
    "                random_state=0)\n",
    "    km.fit(Xtrain)\n",
    "    distortions.append(km.inertia_)\n",
    "    if best_distortion > km.inertia_:\n",
    "        best_distortion = km.inertia_\n",
    "        best_i = i\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f38446",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best i  found:\")\n",
    "print(best_i)\n",
    "print(\"Best distortion  found:\")\n",
    "print(best_distortion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42dbf160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the data\n",
    "plt.plot(range(1, 30), distortions, marker='o')\n",
    "plt.title(\"Elbow Graph\")\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Distortion')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8623f7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "km = KMeans(n_clusters=9,\n",
    "            n_init='auto',\n",
    "            random_state=0)\n",
    "clusters = km.fit_predict(Xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3ceb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NB['clusters'] = clusters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0c96d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16073ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NB['labelnames'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525af6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NB[\n",
    "    df_NB['types'] == 'multipart/alternative'].email_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5df1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(Xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34644a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f95cf3f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "New_Xtrain = np.hstack((Xtrain, clusters.reshape(-1, 1)))\n",
    "New_Xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7207a623",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_array = np.array(df_NB['clusters'])\n",
    "cluster_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9033842",
   "metadata": {},
   "source": [
    "### Naive Bayes Portion\n",
    "\n",
    "##### Using Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b735c285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Naive Bayes\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3230f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data, testing_data = \\\n",
    "    train_test_split(df_NB, test_size=0.2, random_state=25)\n",
    "\n",
    "print(f\"No. of training examples: {training_data.shape[0]}\")\n",
    "print(f\"No. of testing examples: {testing_data.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b9eadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "the_count = CountVectorizer()\n",
    "\n",
    "Xtrain = the_count.fit_transform(training_data['email_body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0851a576",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = Xtrain.toarray(ngram_range=(1, 2))\n",
    "cluster_array = np.array(training_data['clusters'])\n",
    "Xtrain2 = np.hstack((Xtrain, cluster_array.reshape(-1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88917a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Naive Bayes model\n",
    "nb = MultinomialNB(alpha=0.1)\n",
    "nb.fit(Xtrain2, training_data['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ab3f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest = the_count.transform(testing_data['email_body'])\n",
    "Xtest = Xtest.toarray()\n",
    "cluster_array = np.array(testing_data['clusters'])\n",
    "Xtest2 = np.hstack((Xtest, cluster_array.reshape(-1, 1)))\n",
    "preds = nb.predict(Xtest2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48fbde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b28e388",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(testing_data['labels'], preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bef8854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the confusion matrix\n",
    "\n",
    "cnf_matrix = confusion_matrix(testing_data['labels'], preds)\n",
    "\n",
    "print(cnf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9a3003",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sn\n",
    "sn.heatmap(cnf_matrix, annot=True, fmt='d')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1382a0",
   "metadata": {},
   "source": [
    "##### Using TF-IDF Vectorizor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1146ca8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(ngram_range=(1, 2))\n",
    "\n",
    "Xtrain = tfidf.fit_transform(training_data['email_body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af31336",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = Xtrain.toarray()\n",
    "cluster_array = np.array(training_data['clusters'])\n",
    "Xtrain2 = np.hstack((Xtrain, cluster_array.reshape(-1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd6f7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Naive Bayes model\n",
    "nb = MultinomialNB(alpha=0.1)\n",
    "nb.fit(Xtrain2, training_data['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d615d633",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest = the_count.transform(testing_data['email_body'])\n",
    "Xtest = Xtest.toarray()\n",
    "cluster_array = np.array(testing_data['clusters'])\n",
    "Xtest2 = np.hstack((Xtest, cluster_array.reshape(-1, 1)))\n",
    "preds = nb.predict(Xtest2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8326ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc119f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(testing_data['labels'], preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3d6f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the confusion matrix\n",
    "\n",
    "cnf_matrix = confusion_matrix(testing_data['labels'], preds)\n",
    "\n",
    "print(cnf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c83e77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('clf', MultinomialNB()),\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "    'clf__alpha': [0.1, 1, 10],\n",
    "}\n",
    "\n",
    "clf2 = GridSearchCV(text_clf, parameters, cv=5)\n",
    "clf2.fit(training_data['email_body'], training_data['labels'])\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print(clf2.best_params_)\n",
    "\n",
    "preds = clf2.predict(testing_data['email_body'])\n",
    "print(classification_report(testing_data['labels'], preds))\n",
    "\n",
    "cnf2_matrix = confusion_matrix(testing_data['labels'], preds)\n",
    "print(cnf2_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5007519",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf = Pipeline([\n",
    "    ('vect', TfidfVectorizer()),\n",
    "    ('clf', MultinomialNB()),\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "    'clf__alpha': [0.1, 1, 10],\n",
    "}\n",
    "\n",
    "clf2 = GridSearchCV(text_clf, parameters, cv=5)\n",
    "clf2.fit(training_data['email_body'], training_data['labels'])\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print(clf2.best_params_)\n",
    "\n",
    "preds = clf2.predict(testing_data['email_body'])\n",
    "print(classification_report(testing_data['labels'], preds))\n",
    "\n",
    "cnf2_matrix = confusion_matrix(testing_data['labels'], preds)\n",
    "print(cnf2_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc78488",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(df):\n",
    "    count = CountVectorizer()\n",
    "    clf = MultinomialNB(alpha=0.1)\n",
    "    training_data, testing_data = \\\n",
    "        train_test_split(df, test_size=0.2, random_state=25)\n",
    "    Xtrain = count.fit_transform(training_data['email_body'])\n",
    "    Xtrain = Xtrain.toarray()\n",
    "    cluster_array = np.array(training_data['clusters'])\n",
    "    Xtrain2 = np.hstack((Xtrain, cluster_array.reshape(-1, 1)))\n",
    "    clf.fit(Xtrain2, training_data['labels'])\n",
    "    Xtest = count.transform(testing_data['email_body'])\n",
    "    Xtest = Xtest.toarray()\n",
    "    cluster_array = np.array(testing_data['clusters'])\n",
    "    Xtest2 = np.hstack((Xtest, cluster_array.reshape(-1, 1)))\n",
    "    preds = clf.predict(Xtest2)\n",
    "    cnf2_matrix = confusion_matrix(testing_data['labels'], preds)\n",
    "    return print(classification_report(testing_data['labels'], preds),\n",
    "                 cnf2_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876ad22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df_from_file(path):\n",
    "    file_name = []\n",
    "    contents = []\n",
    "    types = []\n",
    "    labels = []\n",
    "    labelnames = []\n",
    "    message = ''\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for name in files:\n",
    "            with open(os.path.join(root, name),\n",
    "                      'r', encoding='latin1') as f:\n",
    "                message = ''\n",
    "                try:\n",
    "                    x = email.message_from_file(f)\n",
    "                except UnicodeDecodeError:\n",
    "                    print(\"Error in file: Unknown Error\")\n",
    "                if \"multipart\" in x.get_content_type():\n",
    "                    if x.is_multipart():\n",
    "                        for part in x.get_payload():\n",
    "                            if \"text/plain\" in part.get_content_type():\n",
    "                                message = message + \\\n",
    "                                    (part.get_payload()\n",
    "                                     .replace(\"\\t\", \"\")\n",
    "                                     .replace(\"\\n\", \" \")\n",
    "                                     .replace(r'http\\S+', ' ')\n",
    "                                     .replace(\"-\", \" \"))\n",
    "                            elif \"text/html\" in part.get_content_type():\n",
    "                                message = message + \\\n",
    "                                    (BS4(part.get_payload())\n",
    "                                     .get_text()\n",
    "                                     .replace(\"\\t\", \"\")\n",
    "                                     .replace(r'http\\S+', ' ')\n",
    "                                     .replace(\"\\n\", \" \")\n",
    "                                     .replace(\"-\", \" \"))\n",
    "                    contents.append(message.replace(\"\\n\", \" \")\n",
    "                                    .replace(\"\\t\", \"\")\n",
    "                                    .replace(r'http\\S+', ' ')\n",
    "                                    .replace(\"-\", \" \"))\n",
    "                elif \"text/plain\" in x.get_content_type():\n",
    "                    contents.append(x.get_payload()\n",
    "                                    .replace(\"\\n\", \" \")\n",
    "                                    .replace(r'http\\S+', ' ')\n",
    "                                    .replace(\"-\", \" \"))\n",
    "                elif \"text/html\" in x.get_content_type():\n",
    "                    contents.append(BS4(x.get_payload())\n",
    "                                    .get_text()\n",
    "                                    .replace(r'http\\S+', ' ')\n",
    "                                    .replace(\"\\n\", \" \")\n",
    "                                    .replace(\"-\", \" \"))\n",
    "                types.append(x.get_content_type())\n",
    "                if \"ham\" in root:\n",
    "                    labelnames.append('ham')\n",
    "                    labels.append(1)\n",
    "                elif \"spam\" in root:\n",
    "                    labelnames.append('spam')\n",
    "                    labels.append(0)\n",
    "                file_name.append(os.path.join(root, name))\n",
    "    df_NB = pd.DataFrame()\n",
    "    df_NB['Filename'] = file_name\n",
    "    df_NB['types'] = types\n",
    "    df_NB['email_body'] = contents\n",
    "    df_NB['labelnames'] = labelnames\n",
    "    df_NB['labels'] = labels\n",
    "    the_count = CountVectorizer()\n",
    "    Xtrain = the_count.fit_transform(df_NB['email_body'])\n",
    "    Xtrain = Xtrain.toarray()\n",
    "    km = KMeans(n_clusters=9,\n",
    "                n_init='auto',\n",
    "                random_state=0)\n",
    "    clusters = km.fit_predict(Xtrain)\n",
    "    df_NB['clusters'] = clusters\n",
    "    return df_NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04d4ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "New_df = create_df_from_file(\".\\\\SpamAssassinMessages\")\n",
    "New_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e834e08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction(New_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5baa17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79e4b63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e998a3b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83165914",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "QTW",
   "language": "python",
   "name": "qtw"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
